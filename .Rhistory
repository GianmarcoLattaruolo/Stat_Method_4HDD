setwd("C:/Users/latta/UNI/corsi_magistrale/Statistical Methods 4HDD/project/ad-dataset")
tb <- read.table("ad.data")
tm ?
f
?tm
?? tm
data <- read.csv("labelled_newscatcher_dataset.csv", row.names=NULL, sep=';')
#install.packages('tm')
library(tm)
library(glmnet)
setwd("C:\\Users\\latta\\GitHub\\Stat_Method_4HDD")
data <- read.csv("labelled_newscatcher_dataset.csv", row.names=NULL, sep=';')
#install.packages('tm')
library(tm)
library(glmnet)
# cleaning the text
corpus = Corpus(VectorSource(data$title))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("news", stopwords("english")))
corpus[[1]][1]
View(data)
knitr
version kniter
corpus[[10]][1]
# creating the frequencies matrix
frequencies = DocumentTermMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.995)
tSparse = as.data.frame(as.matrix(sparse))
colnames(tSparse) = make.names(colnames(tSparse))
tSparse$topic = as.factor(data$topic)
data$title[10]
corpus[[10]]
corpus[[10]][1]
# cleaning the text
corpus = Corpus(VectorSource(data$title))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("news", stopwords("english")))
data$title[10]
corpus[[10]][1]
# cleaning the text
corpus = Corpus(VectorSource(data$title))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("news", stopwords("english")))
#data$title[10]
corpus[[10]][1]
# cleaning the text
corpus = Corpus(VectorSource(data$title))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("news", stopwords("english")))
#data$title[10]
corpus[[10]][1]
# cleaning the text
corpus = Corpus(VectorSource(data$title))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("news", stopwords("english")))
#data$title[10]
corpus[[10]][1]
#data$title[10]
corpus[[10]][1][1]
# cleaning the text
corpus = Corpus(VectorSource(data$title))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("news", stopwords("english")))
data$title[10]
corpus[[10]][1]
View(corpus)
corpus[[10]][1]$value
corpus[[10]][1]$content
data$title[10]
corpus[[10]][1]$content
rm(data)
corpus[["10"]][["meta"]][["datetimestamp"]][[1]][[1]][[1]][[1]][[1]][[1]][[1]][[1]][[1]]
?DocumentTermMatrix
View(frequencies)
View(sparse)
View(tSparse)
# creating the frequencies matrix
frequencies = DocumentTermMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.995)
tSparse = as.data.frame(as.matrix(sparse))
colnames(tSparse) = make.names(colnames(tSparse))
tSparse$topic = as.factor(data$topic)
data <- read.csv("labelled_newscatcher_dataset.csv", row.names=NULL, sep=';')
#install.packages('tm')
library(tm)
library(glmnet)
%>%
