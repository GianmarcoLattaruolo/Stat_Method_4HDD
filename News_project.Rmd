---
title: "News classification"
subtitle: "Statistical MEthods for High Dimensional Data Project"
author: "add your name"
font: 12pt
output:
  html_document: 
    toc: yes
  pdf_document: 
    toc: yes
    toc_depth: 4
editor_options: 
  chunk_output_type: inline
---

# 1. The dataset


```{r import data}
data <- read.csv("labelled_newscatcher_dataset.csv", row.names=NULL, sep=';')

#install.packages('tm')
library(tm)
library(glmnet)
```

## 1.1 Dataset description


Â 


```{r load data, warning=FALSE}

```



## 1.2 Cleaning


```{r clean NULL variables}

# cleaning the text
corpus = Corpus(VectorSource(data$title))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("news", stopwords("english")))

corpus[[1]][1]


```


# 2. Data exploration

## 2.1 Summary


```{r summary of the data, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
# creating the frequencies matrix
frequencies = DocumentTermMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.995)
tSparse = as.data.frame(as.matrix(sparse))
colnames(tSparse) = make.names(colnames(tSparse))
tSparse$topic = as.factor(data$topic)

```



## 3.1 Generalized linear model

Using a generalized linear model from library `glm` we can fit our data and after this update the model.
$$
logit(x)=\ln\left(\frac{x}{1-x}\right)
$$
\
```{r glm applied, warning=FALSE}
 
# train test split
set.seed(123)
size <- floor(0.8 * nrow(tSparse))
mask <- sample(seq_len(nrow(tSparse)), size=size)
train <- tSparse[mask, ]
test <- tSparse[-mask, ]

train$topic

train2 <- train[,!names(train) %in% c("topic")]
test2 <- test[,!names(test) %in% c("topic")]

lm<- cv.glmnet(train2,train$topic, family= "multinomial",nfolds = 3,grouped = TRUE,type.measure = "class")

pred.train <- predict(lm)
pred.test <- predict(lm, newdata = test2)

table(train$topic, pred.train)
table(test$topic, pred.test)
```
\
